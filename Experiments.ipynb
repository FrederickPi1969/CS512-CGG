{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                             | 84/5000 [00:00<00:12, 398.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n",
      "\n",
      "============= Generating Data ===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:13<00:00, 382.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils_for_experiments import *\n",
    "# from transform_wrappers_multiprocessing import *\n",
    "from transform_wrappers import *\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from discretize import *\n",
    "from visualization import *\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    device = \"cpu\"\n",
    "    print(f\"using device {device}\")\n",
    "\n",
    "    ####################     Generation parameters     #######################################################\n",
    "    dataArgs = dict()\n",
    "\n",
    "    maximum_number_of_nodes_n = \"20\" #@param [12, 24, 30, 48]\n",
    "    dataArgs[\"max_n_node\"] = int(maximum_number_of_nodes_n)\n",
    "\n",
    "    range_of_linkage_probability_p = \"0.0, 1.0\" #@param [[0.0,1.0], [0.2,0.8], [0.5,0.5]]\n",
    "    dataArgs[\"p_range\"] = [float(range_of_linkage_probability_p.split(\",\")[0]), float(range_of_linkage_probability_p.split(\",\")[1])]\n",
    "\n",
    "    node_attributes = \"degree\" #@param [\"uniform\", \"degree\", \"random\"]\n",
    "    dataArgs[\"node_attr\"] = node_attributes\n",
    "\n",
    "    number_of_graph_instances = \"5000\" #@param [1, 100, 1000, 10000, 25000, 50000, 100000, 200000, 500000, 1000000]\n",
    "    dataArgs[\"n_graph\"] = int(number_of_graph_instances)\n",
    "\n",
    "    dataArgs[\"upper_triangular\"] = False\n",
    "    A, Attr, Param, Topol = generate_data_v2(dataArgs)\n",
    "    # g, a, attr = unpad_data(A[0], Attr[0])\n",
    "\n",
    "    ####################     Model parameters     #######################################################\n",
    "    modelArgs = {\"gnn_filters\": 2, \"conv_filters\": 16, \"kernel_size\": 3}\n",
    "\n",
    "    number_of_latent_variables= \"20\" #@param [1, 2, 3, 4, 5]\n",
    "    modelArgs[\"latent_dim\"] = int(number_of_latent_variables)\n",
    "\n",
    "    trainArgs = dict()\n",
    "\n",
    "    weight_graph_reconstruction_loss = \"30\" #@param [0, 1, 2, 3, 5, 10, 20]\n",
    "    weight_attribute_reconstruction_loss = \"5\" #@param [0, 1, 2, 3, 5, 10, 20]\n",
    "    beta_value = \"20\" #@param [0, 1, 2, 3, 5, 10, 20]\n",
    "    trainArgs[\"loss_weights\"] = [int(weight_graph_reconstruction_loss), int(weight_attribute_reconstruction_loss), int(beta_value)]\n",
    "\n",
    "    epochs = \"35\" #@param [10, 20, 50]\n",
    "    trainArgs[\"epochs\"] = int(epochs)\n",
    "    batch_size = \"512\" #@param [2, 4, 8, 16, 32, 128, 512, 1024]\n",
    "    trainArgs[\"batch_size\"] = int(batch_size)\n",
    "    early_stop = \"2\" #@param [1, 2, 3, 4, 10]\n",
    "    trainArgs[\"early_stop\"] = int(early_stop)\n",
    "    train_test_split = \"0.2\" #@param [0.1, 0.2, 0.3, 0.5]\n",
    "    train_validation_split = \"0.1\" #@param [0.1, 0.2, 0.3, 0.5]\n",
    "    trainArgs[\"data_split\"] = float(train_test_split)\n",
    "    trainArgs[\"validation_split\"] = float(train_validation_split)\n",
    "    lr = \"0.001\"  #@param [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    trainArgs[\"lr\"] = float(lr)\n",
    "\n",
    "\n",
    "\n",
    "    ## Train and Test Split _______________________________________________\n",
    "\n",
    "    A_train = torch.from_numpy(A[:int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*A.shape[0])])\n",
    "    Attr_train = generate_batch(torch.from_numpy(Attr[:int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*Attr.shape[0])]), trainArgs[\"batch_size\"])\n",
    "    Param_train = generate_batch(torch.from_numpy(Param[:int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*Param.shape[0])]), trainArgs[\"batch_size\"])\n",
    "    Topol_train = generate_batch(torch.from_numpy(Topol[:int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*Topol.shape[0])]), trainArgs[\"batch_size\"])\n",
    "\n",
    "    A_validate = torch.from_numpy(A[int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*A.shape[0]):int((1-trainArgs[\"data_split\"])*Attr.shape[0])])\n",
    "    Attr_validate = generate_batch(torch.from_numpy(Attr[int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*Attr.shape[0]):int((1-trainArgs[\"data_split\"])*Attr.shape[0])]), trainArgs[\"batch_size\"])\n",
    "    Param_validate = generate_batch(torch.from_numpy(Param[int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*Param.shape[0]):int((1-trainArgs[\"data_split\"])*Attr.shape[0])]), trainArgs[\"batch_size\"])\n",
    "    Topol_validate = generate_batch(torch.from_numpy(Topol[int((1-trainArgs[\"data_split\"]-trainArgs[\"validation_split\"])*Topol.shape[0]):int((1-trainArgs[\"data_split\"])*Attr.shape[0])]), trainArgs[\"batch_size\"])\n",
    "\n",
    "    A_test = torch.from_numpy(A[int((1-trainArgs[\"data_split\"])*A.shape[0]):])\n",
    "    Attr_test = generate_batch(torch.from_numpy(Attr[int((1-trainArgs[\"data_split\"])*Attr.shape[0]):]), trainArgs[\"batch_size\"])\n",
    "    Param_test = generate_batch(torch.from_numpy(Param[int((1-trainArgs[\"data_split\"])*Param.shape[0]):]), trainArgs[\"batch_size\"])\n",
    "    Topol_test = generate_batch(torch.from_numpy(Topol[int((1-trainArgs[\"data_split\"])*Topol.shape[0]):]), trainArgs[\"batch_size\"])\n",
    "\n",
    "\n",
    "    # print(A_train.shape)\n",
    "    # print(len(Attr_train), Attr_train[0].shape)\n",
    "\n",
    "    ## build graph_conv_filters\n",
    "    SYM_NORM = True\n",
    "    A_train_mod = generate_batch(preprocess_adj_tensor_with_identity(torch.squeeze(A_train, -1), SYM_NORM), trainArgs[\"batch_size\"])\n",
    "    A_validate_mod = generate_batch(preprocess_adj_tensor_with_identity(torch.squeeze(A_validate, -1), SYM_NORM), trainArgs[\"batch_size\"])\n",
    "    A_test_mod = generate_batch(preprocess_adj_tensor_with_identity(torch.squeeze(A_test, -1), SYM_NORM), trainArgs[\"batch_size\"])\n",
    "\n",
    "    A_train = generate_batch(A_train, trainArgs[\"batch_size\"])\n",
    "    A_validate = generate_batch(A_validate, trainArgs[\"batch_size\"])\n",
    "    A_test = generate_batch(A_test, trainArgs[\"batch_size\"])\n",
    "\n",
    "    train_data = (Attr_train, A_train_mod, Param_train, Topol_train)\n",
    "    validate_data = (Attr_validate, A_validate_mod, Param_validate, Topol_validate)\n",
    "    test_data = (Attr_test, A_test_mod, Param_test, Topol_test)\n",
    "\n",
    "    # attribute first -> (n, n), adjacency second -> (n, n, 1)\n",
    "    modelArgs[\"input_shape\"], modelArgs[\"output_shape\"] = ((Attr_train[0].shape[1], Attr_train[0].shape[2]), (int(A_train_mod[0].shape[1] / modelArgs[\"gnn_filters\"]), A_train_mod[0].shape[2], 1)),\\\n",
    "                                                          ((Attr_test[0].shape[1], Attr_test[0].shape[1]), (int(A_test_mod[0].shape[1] / modelArgs[\"gnn_filters\"]), A_test_mod[0].shape[2], 1))\n",
    "    # print(modelArgs[\"input_shape\"], modelArgs[\"output_shape\"])\n",
    "    # print(A_train[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr = Attr_train[0][2].float()\n",
    "# f = A_train_mod[0][2].float()\n",
    "# # f = preprocess_adj_tensor_with_identity(torch.squeeze(f, -1), symmetric = False)\n",
    "# z, z_mean, z_log_var, A_hat, attr_hat, A_hat_raw, max_score_per_node, min_score_per_node  = vae(attr.unsqueeze(0), f.unsqueeze(0))\n",
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " =================Extracting useful information=====================\n",
      "Model loss 2430.152518136161 \n",
      "VAE performance:  \n",
      " Accuracy: 0.9069385714285654,  \n",
      " Precision: 0.7047642453256331,  \n",
      " Recall: 0.8931318175829427,  \n",
      " F1 Score: 0.7878451997051672\n",
      "\n",
      "--- Truth topology (averaged) ---\n",
      " density: 0.25517142857142794 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.2777762870649428 \n",
      " edges: 48.482571428571426 \n",
      " avgerage degree 0.25517142857142794\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.3268285714285696 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4490918726394994 \n",
      " edges: 62.09742857142857 \n",
      " avgerage degree 0.3268285714285696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################      VAE        ##########################################\n",
    "operation_name = \"density\"  ## [\"transitivity\", \"density\", \"forest fire ...\"]\n",
    "# param_path = operation_name + \"_pretrained\" + \"_\" + maximum_number_of_nodes_n\n",
    "param_path = \".\"\n",
    "vae = torch.load(param_path + \"/vae.model\")\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "batched_z = []\n",
    "batched_A_hat = []\n",
    "batched_Attr_hat = []\n",
    "batched_A_hat_discretized = []\n",
    "batched_A_hat_discretized_test = []\n",
    "batched_gcn_filters_from_A_hat = []\n",
    "batched_z_test = []\n",
    "batched_A_hat_test = []\n",
    "batched_Attr_hat_test = []\n",
    "batched_gcn_filters_from_A_hat_test = []\n",
    "batched_A_hat_raw_train = []\n",
    "batched_A_hat_raw_test = []\n",
    "batched_A_hat_max_train = []\n",
    "batched_A_hat_max_test = []\n",
    "batched_A_hat_min_train = []\n",
    "batched_A_hat_min_test = []\n",
    "print(\"\\n\\n =================Extracting useful information=====================\")\n",
    "vae.eval()\n",
    "\n",
    "def index_of(my_list, target):\n",
    "    try: return my_list.index(target)\n",
    "    except: return dataArgs[\"max_n_node\"]\n",
    "\n",
    "for e in range(1):\n",
    "    loss_cum = 0\n",
    "    for i in range(len(Attr_train)):\n",
    "        attr = Attr_train[i].float().to(device)\n",
    "        A = A_train[i].float().to(device)\n",
    "        graph_conv_filters = A_train_mod[i].float().to(device)\n",
    "\n",
    "        z, z_mean, z_log_var, A_hat, attr_hat, A_hat_raw, max_score_per_node, min_score_per_node = vae(attr, graph_conv_filters)\n",
    "\n",
    "        if e + 1 == 1:\n",
    "            batched_z.append(z.detach())\n",
    "            batched_Attr_hat.append(attr_hat.detach())\n",
    "            batched_A_hat.append(A_hat.detach())\n",
    "            temp = A_hat.detach().cpu()\n",
    "            batched_gcn_filters_from_A_hat.append(preprocess_adj_tensor_with_identity(torch.squeeze(temp, -1), symmetric = False))\n",
    "\n",
    "            A_discretize = A.cpu().squeeze().numpy()\n",
    "            A_hat_discretize = A_hat.detach().cpu().squeeze().numpy()\n",
    "            discretizer = Discretizer(A_discretize, A_hat_discretize)\n",
    "            A_hat_discretize = discretizer.discretize(method='hard_threshold', threshold=0.4)\n",
    "            A_hat_discretize = torch.unsqueeze(torch.from_numpy(A_hat_discretize), -1)\n",
    "\n",
    "            batched_A_hat_discretized.append(A_hat_discretize)\n",
    "            batched_A_hat_raw_train.append(A_hat_raw.detach())\n",
    "            batched_A_hat_max_train.append(max_score_per_node.detach())\n",
    "            batched_A_hat_min_train.append(min_score_per_node.detach())\n",
    "\n",
    "            # count = 0\n",
    "            for j in range(len(batched_A_hat_discretized[i])):\n",
    "                temp = list(torch.diag(batched_A_hat_discretized[i][j].detach().reshape(dataArgs[\"max_n_node\"], -1)))[::-1]\n",
    "                pred_node_num = dataArgs[\"max_n_node\"] - index_of(list(temp), 1)\n",
    "                Param_train[i][j][-1] = pred_node_num  # predicted node num have ~96% acc\n",
    "                true_node_num = int(Param_train[i][j][0])\n",
    "                # print(pred_node_num)\n",
    "                # print(true_node_num)\n",
    "\n",
    "                # count += pred_node_num == true_node_num\n",
    "            # print(f\"node prediction accuracy : {count / len(batched_A_hat_discretized[i])}\")\n",
    "\n",
    "        loss = loss_func((A, attr), (A_hat, attr_hat), z_mean, z_log_var, trainArgs, modelArgs)\n",
    "        loss_cum += loss.item()\n",
    "\n",
    "    print(\"Model loss {} \".format(loss_cum / len(Attr_train)))\n",
    "\n",
    "\n",
    "a,p,r,f = compute_score_batched(A_train, batched_A_hat_discretized)\n",
    "print(f\"VAE performance:  \\n Accuracy: {a},  \\n Precision: {p},  \\n Recall: {r},  \\n F1 Score: {f}\\n\")\n",
    "\n",
    "density_ori, diameter_ori, cluster_coef_ori, edges_ori, avg_degree_ori = topological_measure(A_train)\n",
    "density_hat, diameter_hat, cluster_coef_hat, edges_hat, avg_degree_hat = topological_measure(batched_A_hat_discretized)\n",
    "print(f\"--- Truth topology (averaged) ---\\n density: {density_ori} \\n diameter: {diameter_ori} \"\n",
    "      f\"\\n clustering coefficient: {cluster_coef_ori} \\n edges: {edges_ori} \\n avgerage degree {avg_degree_ori}\\n\")\n",
    "print(f\"--- Reconstructed topology (averaged) ---\\n density: {density_hat} \\n diameter: {diameter_hat} \"\n",
    "      f\"\\n clustering coefficient: {cluster_coef_hat} \\n edges: {edges_hat} \\n avgerage degree {avg_degree_hat}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ############################# Steering GAN   ####################################\n",
    "\n",
    "# ## training tip: same batch, same alpha!\n",
    "\n",
    "# # w = torch.randn_like(batched_z[0][0], requires_grad=True).unsqueeze(0).to(device)\n",
    "# w = torch.load(param_path + \"/w_density.pt\")\n",
    "# a_w1 = torch.load(param_path + \"/a_w1_density.pt\")\n",
    "# a_w2 = torch.load(param_path + \"/a_w2_density.pt\")\n",
    "# a_b1 = torch.load(param_path + \"/a_b1_density.pt\")\n",
    "# a_b2 = torch.load(param_path + \"/a_b2_density.pt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### Initialize generator\n",
    "# generator = Decoder_v2(modelArgs, trainArgs, device).to(device)\n",
    "\n",
    "# decoder_weight = dict(vae.decoder.named_parameters())\n",
    "# generator_weight = dict(generator.named_parameters())\n",
    "# for k in generator_weight.keys():\n",
    "#     assert k in decoder_weight\n",
    "#     generator_weight[k] = decoder_weight[k]\n",
    "# generator.eval()\n",
    "\n",
    "\n",
    "# discriminator.eval()\n",
    "## operation = \"transitivity\", \"density\", \"node_count\"\n",
    "\n",
    "generator = torch.load(\"generator.model\")\n",
    "\n",
    "# transform = GraphTransform(dataArgs[\"max_n_node\"], operation = operation_name, sigmoid = False)\n",
    "transform = GraphTransform(dataArgs[\"max_n_node\"], operation = operation_name, sigmoid = False)\n",
    "w_epochs = 1  ### adjust epoch here!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8e5d31fe0475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m#         gen_A, gen_attr, gen_A_raw, gen_A_max, gen_A_min = generator(z + alpha_gen * w)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mgen_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_attr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_A_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_A_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_A_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;31m#         temp = gen_A.detach().cpu()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#         gen_fil = preprocess_adj_tensor_with_identity(torch.squeeze(temp, -1), symmetric = False).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'z'"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_train = []\n",
    "w_A_train = []\n",
    "w_A_hat_train = []\n",
    "w_edit_A_hat_train = []\n",
    "w_gen_A_hat_train = []\n",
    "gen_A_raw_train = []\n",
    "gen_A_max_train = []\n",
    "gen_A_min_train = []\n",
    "masked_norm_A_hats = []\n",
    "\n",
    "for e in range(w_epochs):\n",
    "    for i in tqdm(range(len(batched_A_hat_discretized))):\n",
    "\n",
    "        fil = batched_gcn_filters_from_A_hat[i].float().to(device)\n",
    "        attr_hat = batched_Attr_hat[i].float().to(device)\n",
    "        # A_hat = batched_A_hat[i].to(device)\n",
    "        A_hat = batched_A_hat_discretized[i].to(device)\n",
    "        A = A_train[i]\n",
    "        z = batched_z[i].to(device)\n",
    "\n",
    "        ## discretize\n",
    "        # A = A_train[i].cpu().numpy().squeeze(-1)\n",
    "        # A_hat = A_hat.cpu().numpy().squeeze(-1)\n",
    "        # discretizer = Discretizer(A, A_hat)\n",
    "        # A_hat = discretizer.discretize('hard_threshold')\n",
    "        # A = torch.unsqueeze(torch.from_numpy(A), -1)\n",
    "        # A_hat = torch.unsqueeze(torch.from_numpy(A_hat), -1)\n",
    "\n",
    "#         _, alpha_edit = transform.get_train_alpha(A_hat)\n",
    "        _, alpha_edit = 0, 0.35\n",
    "        # alpha_gen = a_w2 * F.relu(a_w1 * alpha_edit + a_b1) + a_b2\n",
    "        sign = 1 if alpha_edit < 0 else -1\n",
    "        alpha_gen = sign * torch.log(torch.abs(torch.tensor(alpha_edit)))\n",
    "\n",
    "        ## first get edit and D(edit(G(z)))\n",
    "        \n",
    "        \n",
    "        edit_attr = attr_hat\n",
    "        edit_A = transform.get_target_graph(alpha_edit, A_hat, list(Param_train[i][:,-1].type(torch.LongTensor)))  # replace this with the edit(G(z)) attr & filter! Expect do all graphs in batch in one step!!\n",
    "        # print(alpha_edit, alpha_gen)\n",
    "\n",
    "#         temp = edit_A.detach().cpu()\n",
    "#         edit_fil = preprocess_adj_tensor_with_identity(torch.squeeze(temp, -1), symmetric = False).to(device)\n",
    "#         feature_edit, _ = discriminator(edit_attr.float(), edit_fil.float())\n",
    "\n",
    "\n",
    "        # Then get G(z + aw) and D(G(z + aw))\n",
    "    \n",
    "#         gen_A, gen_attr, gen_A_raw, gen_A_max, gen_A_min = generator(z + alpha_gen * w)\n",
    "        gen_A, gen_attr, gen_A_raw, gen_A_max, gen_A_min = generator(alpha_gen, z)\n",
    "#         temp = gen_A.detach().cpu()\n",
    "#         gen_fil = preprocess_adj_tensor_with_identity(torch.squeeze(temp, -1), symmetric = False).to(device)\n",
    "#         feature_gen, preds = discriminator(gen_attr.float(), gen_fil.float())\n",
    "#         labels = torch.ones(edit_attr.shape[0]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "        if e + 1 == w_epochs:\n",
    "            w_A_train.append(A)\n",
    "            w_A_hat_train.append(A_hat)\n",
    "            w_edit_A_hat_train.append(edit_A)\n",
    "            w_gen_A_hat_train.append(gen_A.detach())\n",
    "            gen_A_raw_train.append(gen_A_raw.detach())\n",
    "            masked_norm_A = masked_normalization(gen_A_raw.detach(), Param_train[i])\n",
    "            masked_norm_A_hats.append(masked_norm_A)\n",
    "            gen_A_max_train.append(gen_A_max.detach())\n",
    "            gen_A_min_train.append(gen_A_min.detach())\n",
    "\n",
    "print(\"====================== G(z + aw) v.s. edit(G(z))  results =============================\")\n",
    "gen_A_discretized = debugDiscretizer(w_A_hat_train, w_edit_A_hat_train, gen_A_raw_train, gen_A_max_train, gen_A_min_train, w_gen_A_hat_train, masked_norm_A_hats, discretize_method=\"hard_threshold\", printMatrix=False, abortPickle=True)\n",
    "\n",
    "\n",
    "#debugDecoder(w_edit_A_hat_train, [], w_gen_A_hat_train, [], discretize_method=\"hard_threshold\", printMatrix=True)\n",
    "# drawGraph(w_A_train, w_A_hat_train, w_edit_A_hat_train, w_gen_A_hat_train)\n",
    "# drawGraphSaveFigure(w_A_train, w_A_hat_train, w_edit_A_hat_train, w_gen_A_hat_train, clearImage=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original topology (averaged) ---\n",
      " density: 0.23133233082706686 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.40446849661076467 \n",
      " edges: 43.95314285714286 \n",
      " avgerage degree 0.23133233082706683\n",
      "\n",
      "--- Edit topology (averaged) ---\n",
      " density: 0.3704706766917278 \n",
      " diameter: -0.9988571428571429 \n",
      " clustering coefficient: 0.5145780875193894 \n",
      " edges: 70.38942857142857 \n",
      " avgerage degree 0.3704706766917278\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.2622511278195479 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.3949161427834552 \n",
      " edges: 49.827714285714286 \n",
      " avgerage degree 0.2622511278195479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "density_ori, diameter_ori, cluster_coef_ori, edges_ori, avg_degree_ori = topological_measure(batched_A_hat_discretized) # G(z)\n",
    "density_ed, diameter_ed, cluster_coef_ed, edges_ed, avg_degree_ed = topological_measure(w_edit_A_hat_train) # edit(G(z), edit_alpha)\n",
    "density_hat, diameter_hat, cluster_coef_hat, edges_hat, avg_degree_hat = topological_measure([torch.from_numpy(gen_A_discretized)]) # G(z + alpaha * w)\n",
    "print(f\"--- Original topology (averaged) ---\\n density: {density_ori} \\n diameter: {diameter_ori} \"\n",
    "      f\"\\n clustering coefficient: {cluster_coef_ori} \\n edges: {edges_ori} \\n avgerage degree {avg_degree_ori}\\n\")\n",
    "\n",
    "print(f\"--- Edit topology (averaged) ---\\n density: {density_ed} \\n diameter: {diameter_ed} \"\n",
    "      f\"\\n clustering coefficient: {cluster_coef_ed} \\n edges: {edges_ed} \\n avgerage degree {avg_degree_ed}\\n\")\n",
    "\n",
    "print(f\"--- Reconstructed topology (averaged) ---\\n density: {density_hat} \\n diameter: {diameter_hat} \"\n",
    "      f\"\\n clustering coefficient: {cluster_coef_hat} \\n edges: {edges_hat} \\n avgerage degree {avg_degree_hat}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!==========================edit_alpha = 0.01 ===================================!!!!!!!!!!!!!!\n",
      "tensor(4.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████                                                                        | 1/7 [00:00<00:03,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.5991808176040649\n",
      "Avaerge probability variance: 0.07136798650026321\n",
      "tensor(4.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████                                                            | 2/7 [00:01<00:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6157324314117432\n",
      "Avaerge probability variance: 0.07353327423334122\n",
      "tensor(4.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████                                                | 3/7 [00:01<00:02,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6025481224060059\n",
      "Avaerge probability variance: 0.06679567694664001\n",
      "tensor(4.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:02<00:01,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6228896975517273\n",
      "Avaerge probability variance: 0.06766042113304138\n",
      "tensor(4.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:02<00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.619803786277771\n",
      "Avaerge probability variance: 0.07104763388633728\n",
      "tensor(4.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:03<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6192256808280945\n",
      "Avaerge probability variance: 0.07571703940629959\n",
      "tensor(4.6052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:03<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6169819235801697\n",
      "Avaerge probability variance: 0.07275968044996262\n",
      "====================== G(z + aw) v.s. edit(G(z))  results =============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9609164285714216\n",
      "precision: 0.8719941481555349\n",
      "recall: 0.8670081318237295\n",
      "f1 score: 0.8694939921097394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original topology (averaged) ---\n",
      " density: 0.2665082706766896 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4490918726394994 \n",
      " edges: 50.63657142857143 \n",
      " avgerage degree 0.2665082706766896\n",
      "\n",
      "--- Edit topology (averaged) ---\n",
      " density: 0.3327473684210505 \n",
      " diameter: -0.9991428571428571 \n",
      " clustering coefficient: 0.4588762045238918 \n",
      " edges: 63.222 \n",
      " avgerage degree 0.3327473684210505\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.3352706766917273 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4673617824682325 \n",
      " edges: 63.70142857142857 \n",
      " avgerage degree 0.3352706766917273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!==========================edit_alpha = 0.1 ===================================!!!!!!!!!!!!!!\n",
      "tensor(2.3026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████                                                                        | 1/7 [00:00<00:03,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6047631502151489\n",
      "Avaerge probability variance: 0.0698051005601883\n",
      "tensor(2.3026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████                                                            | 2/7 [00:01<00:02,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6212549209594727\n",
      "Avaerge probability variance: 0.07037972658872604\n",
      "tensor(2.3026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████                                                | 3/7 [00:01<00:02,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6081829071044922\n",
      "Avaerge probability variance: 0.06415673345327377\n",
      "tensor(2.3026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:02<00:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.627957820892334\n",
      "Avaerge probability variance: 0.0653679296374321\n",
      "tensor(2.3026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:02<00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6247804760932922\n",
      "Avaerge probability variance: 0.06949345767498016\n",
      "tensor(2.3026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:03<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6239209771156311\n",
      "Avaerge probability variance: 0.07304003834724426\n",
      "tensor(2.3026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:03<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6222915649414062\n",
      "Avaerge probability variance: 0.07006431370973587\n",
      "====================== G(z + aw) v.s. edit(G(z))  results =============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9574957142857082\n",
      "precision: 0.8974745462874881\n",
      "recall: 0.8405118017032981\n",
      "f1 score: 0.8680596930522559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original topology (averaged) ---\n",
      " density: 0.2665082706766896 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4490918726394994 \n",
      " edges: 50.63657142857143 \n",
      " avgerage degree 0.2665082706766896\n",
      "\n",
      "--- Edit topology (averaged) ---\n",
      " density: 0.35350827067669005 \n",
      " diameter: -0.9985714285714286 \n",
      " clustering coefficient: 0.488731782625577 \n",
      " edges: 67.16657142857143 \n",
      " avgerage degree 0.35350827067669\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.33625864661653965 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4728694258729137 \n",
      " edges: 63.88914285714286 \n",
      " avgerage degree 0.33625864661653965\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!==========================edit_alpha = 0.2 ===================================!!!!!!!!!!!!!!\n",
      "tensor(1.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████                                                                        | 1/7 [00:00<00:03,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6056696772575378\n",
      "Avaerge probability variance: 0.06926167756319046\n",
      "tensor(1.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████                                                            | 2/7 [00:01<00:03,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6227304339408875\n",
      "Avaerge probability variance: 0.06939959526062012\n",
      "tensor(1.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████                                                | 3/7 [00:01<00:02,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6085306406021118\n",
      "Avaerge probability variance: 0.06334429234266281\n",
      "tensor(1.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:02<00:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6286075115203857\n",
      "Avaerge probability variance: 0.06479281187057495\n",
      "tensor(1.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:02<00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6250643730163574\n",
      "Avaerge probability variance: 0.06909868866205215\n",
      "tensor(1.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:03<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6251127123832703\n",
      "Avaerge probability variance: 0.0722828358411789\n",
      "tensor(1.6094)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:03<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6233156323432922\n",
      "Avaerge probability variance: 0.06925950944423676\n",
      "====================== G(z + aw) v.s. edit(G(z))  results =============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.948222857142849\n",
      "precision: 0.9236415813634271\n",
      "recall: 0.8130273267544136\n",
      "f1 score: 0.8648117580327768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original topology (averaged) ---\n",
      " density: 0.2665082706766896 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4490918726394994 \n",
      " edges: 50.63657142857143 \n",
      " avgerage degree 0.2665082706766896\n",
      "\n",
      "--- Edit topology (averaged) ---\n",
      " density: 0.3739428571428541 \n",
      " diameter: -0.9974285714285714 \n",
      " clustering coefficient: 0.5133804087437946 \n",
      " edges: 71.04914285714285 \n",
      " avgerage degree 0.3739428571428541\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.33666466165413295 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.47730550020241286 \n",
      " edges: 63.96628571428572 \n",
      " avgerage degree 0.33666466165413295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!==========================edit_alpha = 0.3 ===================================!!!!!!!!!!!!!!\n",
      "tensor(1.2040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████                                                                        | 1/7 [00:00<00:03,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6061468720436096\n",
      "Avaerge probability variance: 0.06891769170761108\n",
      "tensor(1.2040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████                                                            | 2/7 [00:01<00:03,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6237773895263672\n",
      "Avaerge probability variance: 0.06875244528055191\n",
      "tensor(1.2040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████                                                | 3/7 [00:01<00:02,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6090161204338074\n",
      "Avaerge probability variance: 0.06283501535654068\n",
      "tensor(1.2040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:02<00:01,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6290555000305176\n",
      "Avaerge probability variance: 0.06446446478366852\n",
      "tensor(1.2040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:03<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6252957582473755\n",
      "Avaerge probability variance: 0.06886924803256989\n",
      "tensor(1.2040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:03<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.625827968120575\n",
      "Avaerge probability variance: 0.07181653380393982\n",
      "tensor(1.2040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6241669058799744\n",
      "Avaerge probability variance: 0.06873751431703568\n",
      "====================== G(z + aw) v.s. edit(G(z))  results =============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9374292857142807\n",
      "precision: 0.9399929607239249\n",
      "recall: 0.7926671565396577\n",
      "f1 score: 0.8600665992371064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original topology (averaged) ---\n",
      " density: 0.2665082706766896 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4490918726394994 \n",
      " edges: 50.63657142857143 \n",
      " avgerage degree 0.2665082706766896\n",
      "\n",
      "--- Edit topology (averaged) ---\n",
      " density: 0.39142706766916996 \n",
      " diameter: -0.9977142857142857 \n",
      " clustering coefficient: 0.5311423191801565 \n",
      " edges: 74.37114285714286 \n",
      " avgerage degree 0.39142706766916996\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.33684210526315556 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4798516042827392 \n",
      " edges: 64.0 \n",
      " avgerage degree 0.33684210526315556\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!==========================edit_alpha = 0.4 ===================================!!!!!!!!!!!!!!\n",
      "tensor(0.9163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████                                                                        | 1/7 [00:00<00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6064980030059814\n",
      "Avaerge probability variance: 0.06870473176240921\n",
      "tensor(0.9163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████                                                            | 2/7 [00:01<00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.624734103679657\n",
      "Avaerge probability variance: 0.06827861070632935\n",
      "tensor(0.9163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████                                                | 3/7 [00:01<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6095496416091919\n",
      "Avaerge probability variance: 0.062475547194480896\n",
      "tensor(0.9163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:02<00:01,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6294769644737244\n",
      "Avaerge probability variance: 0.06424878537654877\n",
      "tensor(0.9163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:03<00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6254751682281494\n",
      "Avaerge probability variance: 0.0686982199549675\n",
      "tensor(0.9163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:03<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6264995336532593\n",
      "Avaerge probability variance: 0.07147957384586334\n",
      "tensor(0.9163)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6249455213546753\n",
      "Avaerge probability variance: 0.06835662573575974\n",
      "====================== G(z + aw) v.s. edit(G(z))  results =============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9265264285714221\n",
      "precision: 0.9549406577320975\n",
      "recall: 0.7809836953396978\n",
      "f1 score: 0.8592460637884607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original topology (averaged) ---\n",
      " density: 0.2665082706766896 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4490918726394994 \n",
      " edges: 50.63657142857143 \n",
      " avgerage degree 0.2665082706766896\n",
      "\n",
      "--- Edit topology (averaged) ---\n",
      " density: 0.407442105263155 \n",
      " diameter: -0.9977142857142857 \n",
      " clustering coefficient: 0.5486660316544731 \n",
      " edges: 77.414 \n",
      " avgerage degree 0.407442105263155\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.3388992481202986 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.48340318274629185 \n",
      " edges: 64.39085714285714 \n",
      " avgerage degree 0.3388992481202986\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!!!!!!!!!==========================edit_alpha = 0.5 ===================================!!!!!!!!!!!!!!\n",
      "tensor(0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████████████                                                                        | 1/7 [00:00<00:03,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.606891930103302\n",
      "Avaerge probability variance: 0.06855131685733795\n",
      "tensor(0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████████████████                                                            | 2/7 [00:01<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6256409883499146\n",
      "Avaerge probability variance: 0.06792289763689041\n",
      "tensor(0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████                                                | 3/7 [00:01<00:02,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6101027131080627\n",
      "Avaerge probability variance: 0.0622207410633564\n",
      "tensor(0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:02<00:02,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6298903226852417\n",
      "Avaerge probability variance: 0.0641031265258789\n",
      "tensor(0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:03<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6256153583526611\n",
      "Avaerge probability variance: 0.06856788694858551\n",
      "tensor(0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:03<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.6271616220474243\n",
      "Avaerge probability variance: 0.07122446596622467\n",
      "tensor(0.6931)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaerge probability: 0.625690221786499\n",
      "Avaerge probability variance: 0.06806372851133347\n",
      "====================== G(z + aw) v.s. edit(G(z))  results =============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9188185714285652\n",
      "precision: 0.9656926779194589\n",
      "recall: 0.7794108661044867\n",
      "f1 score: 0.8626094068348745\n",
      "--- Original topology (averaged) ---\n",
      " density: 0.2665082706766896 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4490918726394994 \n",
      " edges: 50.63657142857143 \n",
      " avgerage degree 0.2665082706766896\n",
      "\n",
      "--- Edit topology (averaged) ---\n",
      " density: 0.42026165413533556 \n",
      " diameter: -0.9968571428571429 \n",
      " clustering coefficient: 0.560851759804647 \n",
      " edges: 79.84971428571428 \n",
      " avgerage degree 0.42026165413533556\n",
      "\n",
      "--- Reconstructed topology (averaged) ---\n",
      " density: 0.34321353383458403 \n",
      " diameter: -1.0 \n",
      " clustering coefficient: 0.4869254868520835 \n",
      " edges: 65.21057142857143 \n",
      " avgerage degree 0.34321353383458403\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_norm_A = []\n",
    "global_edit_A = []\n",
    "for idx,alpha in enumerate([0.01, 0.1, 0.2, 0.3, 0.4, 0.5]):\n",
    "    print(f\"!!!!!!!!!!!!!!==========================edit_alpha = {alpha} ===================================!!!!!!!!!!!!!!\")\n",
    "    loss_train = []\n",
    "    w_A_train = []\n",
    "    w_A_hat_train = []\n",
    "    w_edit_A_hat_train = []\n",
    "    w_gen_A_hat_train = []\n",
    "    gen_A_raw_train = []\n",
    "    gen_A_max_train = []\n",
    "    gen_A_min_train = []\n",
    "    masked_norm_A_hats = []\n",
    "#     threshold = 0.5 - 0.05 * (idx + 1)\n",
    "    \n",
    "    for e in range(w_epochs):\n",
    "        for i in tqdm(range(len(batched_A_hat_discretized))):\n",
    "\n",
    "            fil = batched_gcn_filters_from_A_hat[i].float().to(device)\n",
    "            attr_hat = batched_Attr_hat[i].float().to(device)\n",
    "            # A_hat = batched_A_hat[i].to(device)\n",
    "            A_hat = batched_A_hat_discretized[i].to(device)\n",
    "            A = A_train[i]\n",
    "            z = batched_z[i].to(device)\n",
    "            hard_mask = (1 - A_hat).squeeze(-1)\n",
    "\n",
    "            _, alpha_edit = 0, alpha\n",
    "        \n",
    "#             sign = 1 if alpha_edit < 0 else -1\n",
    "            alpha_gen = -1 * torch.log(torch.abs(torch.tensor(alpha_edit)))\n",
    "            print(alpha_gen)\n",
    "\n",
    "            edit_attr = attr_hat\n",
    "            edit_A = transform.get_target_graph(alpha_edit, A_hat, list(Param_train[i][:,-1].type(torch.LongTensor)))  # replace this with the edit(G(z)) attr & filter! Expect do all graphs in batch in one step!!\n",
    "\n",
    "#             gen_A, gen_attr, gen_A_raw, gen_A_max, gen_A_min = generator(z + alpha_gen * w)\n",
    "            gen_A, gen_attr, gen_A_raw, gen_A_max, gen_A_min = generator(alpha_gen, hard_mask, z)\n",
    "\n",
    "            if e + 1 == w_epochs:\n",
    "                w_A_train.append(A)\n",
    "                w_A_hat_train.append(A_hat)\n",
    "                w_edit_A_hat_train.append(edit_A)\n",
    "                w_gen_A_hat_train.append(gen_A.detach())\n",
    "                gen_A_raw_train.append(gen_A_raw.detach())\n",
    "                masked_norm_A = masked_normalization(gen_A_raw.detach(), Param_train[i])\n",
    "                masked_norm_A_hats.append(masked_norm_A)\n",
    "                print(f\"Avaerge probability: {torch.mean(masked_norm_A[masked_norm_A > 1e-3])}\")\n",
    "                print(f\"Avaerge probability variance: {torch.var(masked_norm_A[masked_norm_A > 1e-3])}\")\n",
    "                gen_A_max_train.append(gen_A_max.detach())\n",
    "                gen_A_min_train.append(gen_A_min.detach())\n",
    "                \n",
    "        global_norm_A.append(masked_norm_A_hats)\n",
    "        global_edit_A.append(w_edit_A_hat_train)\n",
    "\n",
    "\n",
    "    print(\"====================== G(z + aw) v.s. edit(G(z))  results =============================\")\n",
    "    gen_A_discretized = debugDiscretizer(w_A_hat_train, w_edit_A_hat_train, gen_A_raw_train, gen_A_max_train, gen_A_min_train, w_gen_A_hat_train, masked_norm_A_hats, discretize_method=\"hard_threshold\", printMatrix=False, abortPickle=True, threshold=0.45)\n",
    "\n",
    "    density_ori, diameter_ori, cluster_coef_ori, edges_ori, avg_degree_ori = topological_measure(batched_A_hat_discretized) # G(z)\n",
    "    density_ed, diameter_ed, cluster_coef_ed, edges_ed, avg_degree_ed = topological_measure(w_edit_A_hat_train) # edit(G(z), edit_alpha)\n",
    "    density_hat, diameter_hat, cluster_coef_hat, edges_hat, avg_degree_hat = topological_measure([torch.from_numpy(gen_A_discretized)]) # G(z + alpaha * w)\n",
    "    print(f\"--- Original topology (averaged) ---\\n density: {density_ori} \\n diameter: {diameter_ori} \"\n",
    "          f\"\\n clustering coefficient: {cluster_coef_ori} \\n edges: {edges_ori} \\n avgerage degree {avg_degree_ori}\\n\")\n",
    "\n",
    "    print(f\"--- Edit topology (averaged) ---\\n density: {density_ed} \\n diameter: {diameter_ed} \"\n",
    "          f\"\\n clustering coefficient: {cluster_coef_ed} \\n edges: {edges_ed} \\n avgerage degree {avg_degree_ed}\\n\")\n",
    "\n",
    "    print(f\"--- Reconstructed topology (averaged) ---\\n density: {density_hat} \\n diameter: {diameter_hat} \"\n",
    "          f\"\\n clustering coefficient: {cluster_coef_hat} \\n edges: {edges_hat} \\n avgerage degree {avg_degree_hat}\\n\")\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0],\n",
       "        [  0,   0,   1],\n",
       "        [  0,   0,   2],\n",
       "        ...,\n",
       "        [427,   5,   3],\n",
       "        [427,   5,   4],\n",
       "        [427,   5,   5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(masked_norm_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4855)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(masked_norm_A[masked_norm_A > 1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compare(i1,i2,i3):\n",
    "    print(global_norm_A[i1][i2][i3].numpy())\n",
    "    print(global_edit_A[i1][i2][i3].squeeze(-1).numpy().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89 0.67 0.61 0.58 0.66 0.63 0.32 0.56 0.55 0.49 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.67 0.86 0.44 0.27 0.76 0.33 0.56 0.47 0.32 0.54 0.14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.64 0.41 0.56 0.39 0.36 0.43 0.13 0.51 0.39 0.41 0.27 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.64 0.27 0.44 0.92 0.36 0.86 0.28 0.31 0.64 0.14 0.72 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.68 0.76 0.38 0.36 0.83 0.41 0.54 0.42 0.39 0.41 0.24 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.69 0.31 0.49 0.92 0.40 0.87 0.28 0.35 0.66 0.17 0.72 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.32 0.57 0.13 0.24 0.54 0.24 0.60 0.16 0.22 0.29 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.59 0.40 0.51 0.31 0.36 0.35 0.13 0.47 0.33 0.40 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.60 0.31 0.43 0.68 0.37 0.66 0.21 0.33 0.53 0.19 0.51 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.48 0.56 0.42 0.14 0.41 0.20 0.26 0.43 0.22 0.51 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.44 0.14 0.31 0.80 0.24 0.74 0.29 0.20 0.51 0.05 0.66 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "[[1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "compare(0,0,124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6931)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90 0.69 0.63 0.60 0.68 0.65 0.33 0.58 0.57 0.50 0.42 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.69 0.88 0.44 0.28 0.79 0.33 0.58 0.45 0.33 0.56 0.15 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.65 0.42 0.58 0.40 0.37 0.44 0.14 0.52 0.40 0.41 0.27 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.63 0.28 0.43 0.91 0.38 0.88 0.27 0.32 0.66 0.14 0.75 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.69 0.79 0.38 0.38 0.85 0.42 0.56 0.40 0.39 0.42 0.25 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.68 0.32 0.47 0.92 0.41 0.90 0.27 0.36 0.68 0.17 0.74 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.33 0.59 0.14 0.24 0.56 0.25 0.62 0.15 0.21 0.28 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.60 0.42 0.52 0.32 0.37 0.36 0.13 0.48 0.34 0.40 0.21 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.60 0.32 0.43 0.68 0.38 0.68 0.21 0.34 0.55 0.20 0.53 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.49 0.57 0.42 0.14 0.42 0.19 0.27 0.42 0.21 0.53 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.44 0.15 0.30 0.79 0.25 0.75 0.24 0.21 0.53 0.05 0.68 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n"
     ]
    }
   ],
   "source": [
    "print(global_norm_A[1][0][124].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0]\n",
      " [0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "========================================================================\n",
      "[[0.67 0.40 0.49 0.60 0.67 0.46 0.56 0.43 0.56 0.32 0.54 0.40 0.56 0.44 0.18 0.54 0.21 0.05 0.00 0.00]\n",
      " [0.40 0.61 0.67 0.36 0.65 0.49 0.37 0.44 0.68 0.30 0.29 0.16 0.32 0.47 0.18 0.22 0.35 0.25 0.00 0.00]\n",
      " [0.49 0.67 0.74 0.43 0.71 0.65 0.36 0.51 0.63 0.32 0.42 0.21 0.38 0.54 0.21 0.27 0.36 0.22 0.00 0.00]\n",
      " [0.60 0.36 0.43 0.79 0.69 0.40 0.38 0.31 0.39 0.58 0.49 0.26 0.55 0.39 0.11 0.52 0.32 0.07 0.00 0.00]\n",
      " [0.60 0.62 0.71 0.69 0.87 0.63 0.29 0.45 0.61 0.63 0.33 0.26 0.43 0.56 0.16 0.29 0.41 0.16 0.00 0.00]\n",
      " [0.46 0.49 0.56 0.40 0.83 0.59 0.30 0.33 0.48 0.17 0.24 0.22 0.34 0.58 0.12 0.34 0.17 0.11 0.00 0.00]\n",
      " [0.10 0.37 0.36 0.13 0.34 0.19 0.55 0.25 0.47 0.23 0.19 0.03 0.25 0.25 0.15 0.03 0.94 0.62 0.00 0.00]\n",
      " [0.43 0.44 0.51 0.31 0.50 0.33 0.40 0.56 0.53 0.32 0.33 0.32 0.17 0.30 0.33 0.33 0.30 0.16 0.00 0.00]\n",
      " [0.25 0.54 0.57 0.26 0.51 0.39 0.47 0.37 0.68 0.24 0.24 0.08 0.38 0.48 0.16 0.11 0.49 0.35 0.00 0.00]\n",
      " [0.32 0.30 0.32 0.46 0.55 0.18 0.35 0.32 0.37 0.87 0.43 0.18 0.19 0.15 0.27 0.14 0.63 0.17 0.00 0.00]\n",
      " [0.54 0.26 0.22 0.49 0.36 0.24 0.44 0.43 0.39 0.43 0.76 0.53 0.39 0.28 0.28 0.53 0.17 0.01 0.00 0.00]\n",
      " [0.40 0.16 0.21 0.26 0.22 0.22 0.33 0.32 0.18 0.18 0.53 0.48 0.23 0.21 0.25 0.52 0.06 0.03 0.00 0.00]\n",
      " [0.44 0.21 0.25 0.55 0.43 0.34 0.37 0.15 0.32 0.37 0.39 0.27 0.54 0.35 0.04 0.45 0.08 0.02 0.00 0.00]\n",
      " [0.44 0.47 0.54 0.39 0.56 0.82 0.29 0.30 0.55 0.15 0.23 0.21 0.39 0.58 0.11 0.33 0.14 0.11 0.00 0.00]\n",
      " [0.18 0.18 0.21 0.11 0.16 0.12 0.17 0.33 0.20 0.27 0.28 0.25 0.08 0.11 0.34 0.17 0.19 0.11 0.00 0.00]\n",
      " [0.50 0.22 0.27 0.34 0.29 0.34 0.39 0.33 0.37 0.18 0.54 0.50 0.33 0.33 0.17 0.74 0.07 0.03 0.00 0.00]\n",
      " [0.21 0.35 0.36 0.32 0.43 0.17 0.38 0.30 0.34 0.63 0.22 0.06 0.16 0.14 0.19 0.07 0.86 0.32 0.00 0.00]\n",
      " [0.05 0.25 0.22 0.07 0.19 0.11 0.47 0.17 0.35 0.17 0.18 0.03 0.21 0.24 0.26 0.03 0.97 0.68 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n"
     ]
    }
   ],
   "source": [
    "i,j = 0,77\n",
    "print(global_edit_A[0][i][j].squeeze(-1).numpy().astype(int))\n",
    "print(\"========================================================================\")\n",
    "print(global_norm_A[0][i][j].squeeze(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "[[0.00 0.04 0.05 0.00 0.00 0.05 -0.19 0.05 -0.11 0.03 0.06 0.04 -0.00 0.05 0.02 0.03 0.02 0.01 0.00 0.00]\n",
      " [0.04 0.00 0.00 0.04 0.00 0.05 0.04 0.05 -0.00 0.03 -0.04 0.02 -0.03 0.05 0.02 0.02 0.04 0.03 0.00 0.00]\n",
      " [0.05 0.00 0.00 0.05 0.00 0.00 0.04 0.00 0.00 0.03 -0.07 0.02 -0.03 0.06 0.02 0.03 0.04 0.02 0.00 0.00]\n",
      " [0.00 0.04 0.05 0.00 0.00 0.04 -0.10 0.03 -0.03 -0.00 0.05 0.03 0.06 0.04 0.01 -0.04 0.03 0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.00 0.00 -0.00 0.03 0.00 0.05 0.00 0.02 0.00 0.04 0.02 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.04 -0.00 0.00 -0.03 0.03 -0.00 0.02 0.03 0.02 0.04 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.01 0.04 0.04 0.01 0.01 0.02 0.00 0.03 0.05 0.02 -0.08 0.00 -0.09 -0.01 0.02 0.00 -0.21 -0.01 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.03 0.00 0.03 -0.04 0.00 -0.04 0.03 0.04 0.03 0.00 0.03 0.00 0.03 0.03 0.02 0.00 0.00]\n",
      " [0.03 0.00 0.00 0.03 0.00 0.04 0.05 0.03 0.00 0.03 -0.07 0.01 -0.10 -0.01 0.02 0.01 -0.03 0.04 0.00 0.00]\n",
      " [0.03 0.03 0.03 0.00 -0.00 0.02 -0.03 0.03 -0.03 0.00 0.05 0.02 0.02 0.02 0.03 0.01 0.00 0.02 0.00 0.00]\n",
      " [0.06 -0.02 0.02 0.05 0.02 0.03 -0.19 -0.01 -0.14 0.05 0.00 0.00 0.04 -0.00 0.03 0.00 0.02 0.00 0.00 0.00]\n",
      " [0.04 0.02 0.02 0.03 0.00 0.02 -0.13 0.03 -0.04 0.02 0.00 0.00 0.02 0.02 0.03 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.00 0.02 0.03 0.06 0.05 0.04 -0.14 0.02 -0.07 -0.06 0.04 0.01 0.00 0.04 0.00 -0.02 0.01 0.00 0.00 0.00]\n",
      " [0.05 0.05 0.06 0.04 0.00 -0.00 -0.03 0.03 -0.04 0.02 0.02 0.02 0.02 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.02 0.02 0.02 0.01 0.02 0.01 0.01 0.00 -0.00 0.03 0.03 0.03 -0.01 0.01 0.00 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.05 0.02 0.03 0.04 0.00 0.04 -0.15 0.03 -0.10 -0.00 0.00 0.00 0.04 0.04 0.02 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.02 0.04 0.04 0.03 0.03 0.02 0.04 0.03 0.04 0.00 -0.01 0.01 -0.03 0.02 0.02 0.01 -0.00 0.03 0.00 0.00]\n",
      " [0.01 0.03 0.02 0.01 0.01 0.01 0.05 0.01 0.04 0.02 -0.07 0.00 -0.08 -0.05 -0.06 0.00 -0.26 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "========================================================================\n",
      "[[0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "[[0.00 0.00 0.00 0.00 -0.00 0.00 -0.08 0.00 -0.05 0.00 0.00 0.00 -0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 -0.02 0.00 -0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 -0.03 0.00 -0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.04 0.00 -0.02 -0.00 0.00 0.00 0.00 0.00 0.00 -0.03 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.02 0.00 -0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 -0.03 0.00 -0.03 -0.01 -0.00 0.00 -0.09 -0.02 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.03 0.00 -0.03 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.03 0.00 -0.04 -0.02 0.00 0.00 -0.02 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 -0.00 -0.02 0.00 -0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 -0.02 0.00 0.00 -0.01 0.00 -0.07 -0.02 -0.05 0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.05 0.00 -0.02 -0.00 0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.05 0.00 -0.03 -0.03 0.00 -0.01 0.00 0.00 0.00 -0.02 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.02 0.00 -0.03 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.01 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.06 0.00 -0.04 -0.01 -0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 -0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 0.00 -0.03 0.00 -0.03 -0.02 -0.03 0.00 -0.11 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "\n",
      "[[0.00 0.04 0.05 0.00 0.00 0.05 -0.27 0.05 -0.16 0.03 0.06 0.04 -0.00 0.05 0.02 0.03 0.02 0.01 0.00 0.00]\n",
      " [0.04 0.00 0.00 0.04 0.00 0.05 0.04 0.05 -0.00 0.03 -0.06 0.02 -0.05 0.05 0.02 0.02 0.04 0.03 0.00 0.00]\n",
      " [0.05 0.00 0.00 0.05 0.00 0.00 0.04 0.00 0.00 0.03 -0.10 0.02 -0.05 0.06 0.02 0.03 0.04 0.02 0.00 0.00]\n",
      " [0.00 0.04 0.05 0.00 0.00 0.04 -0.14 0.03 -0.05 -0.00 0.05 0.03 0.06 0.04 0.01 -0.07 0.03 0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.00 -0.00 -0.00 0.03 -0.00 0.05 0.00 0.02 0.00 0.04 0.02 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.04 -0.00 0.00 -0.04 0.03 -0.02 0.02 0.03 0.02 0.04 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.01 0.04 0.04 0.01 0.00 0.02 0.00 0.03 0.05 0.02 -0.11 0.00 -0.12 -0.02 0.02 0.00 -0.30 -0.04 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.03 0.00 0.03 -0.07 0.00 -0.07 0.03 0.04 0.03 -0.00 0.03 0.00 0.03 0.03 0.02 0.00 0.00]\n",
      " [0.03 0.00 0.00 0.03 0.00 0.04 0.05 0.03 -0.00 0.03 -0.10 0.01 -0.14 -0.03 0.02 0.01 -0.05 0.04 0.00 0.00]\n",
      " [0.03 0.03 0.03 0.00 -0.00 0.02 -0.05 0.03 -0.06 0.00 0.05 0.02 0.02 0.02 0.03 0.01 0.00 0.02 0.00 0.00]\n",
      " [0.06 -0.04 0.02 0.05 0.02 0.03 -0.26 -0.02 -0.19 0.05 0.00 0.00 0.04 -0.01 0.03 0.00 0.02 0.00 0.00 0.00]\n",
      " [0.04 0.02 0.02 0.03 0.00 0.02 -0.18 0.03 -0.06 0.02 0.00 0.00 0.02 0.02 0.03 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.00 0.02 0.03 0.06 0.05 0.04 -0.20 0.02 -0.10 -0.09 0.04 0.00 0.00 0.04 0.00 -0.04 0.01 0.00 0.00 0.00]\n",
      " [0.05 0.05 0.06 0.04 0.00 -0.00 -0.05 0.03 -0.07 0.02 0.02 0.02 0.01 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.02 0.02 0.02 0.01 0.02 0.01 0.01 0.00 -0.01 0.03 0.03 0.03 -0.02 0.01 0.00 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.05 0.02 0.03 0.04 0.00 0.04 -0.21 0.03 -0.15 -0.01 0.00 0.00 0.04 0.04 0.02 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.02 0.04 0.04 0.03 0.03 0.02 0.04 0.03 0.04 0.00 -0.01 0.01 -0.04 0.02 0.02 0.01 -0.00 0.03 0.00 0.00]\n",
      " [0.01 0.03 0.02 0.01 0.00 0.01 0.05 0.01 0.04 0.02 -0.10 0.00 -0.11 -0.07 -0.08 0.00 -0.36 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "========================================================================\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "[[0.00 0.00 0.00 0.00 -0.00 0.00 -0.04 0.00 -0.03 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 -0.02 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.01 -0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.02 -0.01 -0.00 0.00 -0.05 -0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.02 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.02 0.00 -0.02 -0.01 0.00 0.00 -0.01 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 -0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 -0.01 0.00 0.00 -0.00 0.00 -0.04 -0.01 -0.03 0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.03 0.00 -0.01 -0.00 0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.03 0.00 -0.02 -0.02 0.00 -0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.01 0.00 -0.02 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.03 0.00 -0.03 -0.00 -0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 -0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 0.00 -0.02 0.00 -0.02 -0.01 -0.01 0.00 -0.06 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "\n",
      "[[0.00 0.04 0.05 0.00 0.00 0.05 -0.31 0.05 -0.19 0.03 0.06 0.04 -0.00 0.05 0.02 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.04 0.00 0.00 0.04 0.00 0.05 0.04 0.05 -0.00 0.03 -0.07 0.02 -0.06 0.05 0.02 0.02 0.04 0.03 0.00 0.00]\n",
      " [0.05 0.00 0.00 0.05 0.00 -0.00 0.04 0.00 0.00 0.03 -0.12 0.02 -0.06 0.06 0.02 0.03 0.04 0.02 0.00 0.00]\n",
      " [0.00 0.04 0.05 0.00 0.00 0.04 -0.17 0.03 -0.07 -0.00 0.05 0.03 0.06 0.04 0.01 -0.09 0.03 0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.00 -0.00 -0.00 0.03 -0.00 0.05 0.00 0.02 0.00 0.04 0.02 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.04 -0.00 0.00 -0.05 0.03 -0.03 0.02 0.03 0.02 0.04 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.01 0.04 0.04 0.01 -0.00 0.02 0.00 0.03 0.05 0.02 -0.12 0.00 -0.14 -0.03 0.02 0.00 -0.36 -0.05 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.03 0.00 0.03 -0.08 0.00 -0.08 0.03 0.04 0.03 -0.00 0.03 0.00 0.03 0.03 0.02 0.00 0.00]\n",
      " [0.03 0.00 0.00 0.03 0.00 0.04 0.05 0.03 -0.00 0.03 -0.11 0.01 -0.16 -0.04 0.02 0.01 -0.07 0.04 0.00 0.00]\n",
      " [0.03 0.03 0.03 0.00 -0.00 0.02 -0.06 0.03 -0.07 0.00 0.05 0.02 0.02 0.02 0.03 0.01 0.00 0.02 0.00 0.00]\n",
      " [0.06 -0.05 0.02 0.05 0.01 0.03 -0.30 -0.03 -0.22 0.05 0.00 0.00 0.04 -0.02 0.03 0.00 0.02 0.00 0.00 0.00]\n",
      " [0.04 0.02 0.02 0.03 0.00 0.02 -0.21 0.03 -0.07 0.02 0.00 0.00 0.02 0.02 0.03 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.00 0.02 0.03 0.06 0.05 0.04 -0.23 0.02 -0.12 -0.11 0.04 -0.00 0.00 0.04 0.00 -0.05 0.01 0.00 0.00 0.00]\n",
      " [0.05 0.05 0.06 0.04 0.00 -0.00 -0.06 0.03 -0.09 0.02 0.02 0.02 0.01 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.02 0.02 0.02 0.01 0.02 0.01 0.01 0.00 -0.01 0.03 0.03 0.03 -0.02 0.01 0.00 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.05 0.02 0.03 0.04 0.00 0.04 -0.25 0.03 -0.17 -0.02 0.00 0.00 0.04 0.04 0.02 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.02 0.04 0.04 0.03 0.02 0.02 0.04 0.03 0.04 0.00 -0.02 0.01 -0.05 0.02 0.02 0.01 -0.00 0.03 0.00 0.00]\n",
      " [0.01 0.03 0.02 0.01 -0.00 0.01 0.05 0.01 0.04 0.02 -0.12 0.00 -0.13 -0.08 -0.10 0.00 -0.43 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "========================================================================\n",
      "[[0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "[[0.00 0.00 0.00 0.00 -0.00 0.00 -0.03 0.00 -0.02 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.01 -0.00 0.00 0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 -0.01 0.00 -0.01 -0.00 -0.00 0.00 -0.04 -0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.01 0.00 -0.02 -0.01 0.00 0.00 -0.01 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 -0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 -0.01 0.00 0.00 -0.00 0.00 -0.03 -0.01 -0.02 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.01 -0.00 0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.01 -0.01 0.00 -0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.02 -0.00 -0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 0.00 0.00 -0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 0.00 -0.01 0.00 -0.01 -0.01 -0.01 0.00 -0.04 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "\n",
      "[[0.00 0.04 0.05 0.00 0.00 0.05 -0.34 0.05 -0.21 0.03 0.06 0.04 -0.00 0.05 0.02 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.04 0.00 0.00 0.04 0.00 0.05 0.04 0.05 -0.00 0.03 -0.08 0.02 -0.07 0.05 0.02 0.02 0.04 0.03 0.00 0.00]\n",
      " [0.05 0.00 0.00 0.05 0.00 -0.00 0.04 0.00 0.00 0.03 -0.13 0.02 -0.07 0.06 0.02 0.03 0.04 0.02 0.00 0.00]\n",
      " [0.00 0.04 0.05 0.00 0.00 0.04 -0.18 0.03 -0.08 -0.00 0.05 0.03 0.06 0.04 0.01 -0.10 0.03 0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.00 -0.00 -0.00 0.03 -0.00 0.05 0.00 0.02 0.00 0.04 0.02 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.04 -0.00 0.00 -0.06 0.03 -0.03 0.02 0.03 0.02 0.04 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.01 0.04 0.04 0.01 -0.01 0.02 0.00 0.03 0.05 0.02 -0.14 0.00 -0.16 -0.03 0.02 0.00 -0.40 -0.06 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.03 0.00 0.03 -0.09 0.00 -0.10 0.03 0.04 0.03 -0.01 0.03 0.00 0.03 0.03 0.02 0.00 0.00]\n",
      " [0.03 0.00 0.00 0.03 0.00 0.04 0.05 0.03 -0.00 0.03 -0.13 0.01 -0.18 -0.04 0.02 0.01 -0.08 0.04 0.00 0.00]\n",
      " [0.03 0.03 0.03 0.00 -0.00 0.02 -0.07 0.03 -0.08 0.00 0.05 0.02 0.02 0.02 0.03 0.01 0.00 0.02 0.00 0.00]\n",
      " [0.06 -0.06 0.02 0.05 0.01 0.03 -0.33 -0.04 -0.24 0.05 0.00 0.00 0.04 -0.02 0.03 0.00 0.02 0.00 0.00 0.00]\n",
      " [0.04 0.02 0.02 0.03 0.00 0.02 -0.23 0.03 -0.07 0.02 0.00 0.00 0.02 0.02 0.03 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.00 0.02 0.03 0.06 0.05 0.04 -0.25 0.02 -0.13 -0.12 0.04 -0.00 0.00 0.04 0.00 -0.06 0.01 0.00 0.00 0.00]\n",
      " [0.05 0.05 0.06 0.04 0.00 -0.00 -0.06 0.03 -0.10 0.02 0.02 0.02 0.00 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.02 0.02 0.02 0.01 0.02 0.01 0.00 0.00 -0.01 0.03 0.03 0.03 -0.02 0.01 0.00 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.05 0.02 0.03 0.04 0.00 0.04 -0.27 0.03 -0.19 -0.02 0.00 0.00 0.04 0.04 0.02 -0.00 0.01 0.00 0.00 0.00]\n",
      " [0.02 0.04 0.04 0.03 0.02 0.02 0.04 0.03 0.04 0.00 -0.02 0.01 -0.05 0.02 0.02 0.01 -0.00 0.03 0.00 0.00]\n",
      " [0.01 0.03 0.02 0.01 -0.00 0.01 0.05 0.01 0.04 0.02 -0.13 0.00 -0.15 -0.09 -0.11 0.00 -0.47 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "========================================================================\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "[[0.00 0.00 0.00 0.00 -0.00 0.00 -0.02 0.00 -0.02 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.01 0.00 -0.01 -0.00 0.00 0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 -0.01 0.00 -0.01 -0.00 -0.00 0.00 -0.03 -0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.01 0.00 -0.01 -0.01 0.00 0.00 -0.01 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 -0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 -0.01 0.00 0.00 -0.00 0.00 -0.02 -0.01 -0.02 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.01 -0.00 0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.01 -0.01 0.00 -0.00 0.00 0.00 0.00 -0.01 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.01 0.00 -0.01 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 -0.02 0.00 -0.01 -0.00 -0.00 0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00 0.00 0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 -0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 -0.00 0.00 0.00 -0.00 0.00 0.00 -0.01 0.00 -0.01 -0.01 -0.01 0.00 -0.03 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "\n",
      "[[0.00 0.04 0.05 0.00 0.00 0.05 -0.37 0.05 -0.22 0.03 0.06 0.04 -0.00 0.05 0.02 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.04 0.00 0.00 0.04 0.00 0.05 0.04 0.05 -0.00 0.03 -0.09 0.02 -0.07 0.05 0.02 0.02 0.04 0.03 0.00 0.00]\n",
      " [0.05 0.00 0.00 0.05 0.00 -0.00 0.04 0.00 0.00 0.03 -0.14 0.02 -0.08 0.06 0.02 0.03 0.04 0.02 0.00 0.00]\n",
      " [0.00 0.04 0.05 0.00 0.00 0.04 -0.20 0.03 -0.08 -0.00 0.05 0.03 0.06 0.04 0.01 -0.11 0.03 0.01 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.03 0.00 -0.00 -0.00 0.03 -0.00 0.05 0.00 0.02 0.00 0.04 0.02 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.04 -0.00 0.00 -0.07 0.03 -0.04 0.02 0.03 0.02 0.04 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.01 0.04 0.04 0.01 -0.01 0.02 0.00 0.03 0.05 0.02 -0.15 0.00 -0.17 -0.04 0.02 0.00 -0.42 -0.07 0.00 0.00]\n",
      " [0.05 0.05 0.00 0.03 0.00 0.03 -0.10 0.00 -0.10 0.03 0.04 0.03 -0.01 0.03 0.00 0.03 0.03 0.02 0.00 0.00]\n",
      " [0.03 0.00 0.00 0.03 0.00 0.04 0.05 0.03 -0.00 0.03 -0.14 0.01 -0.19 -0.05 0.02 0.01 -0.09 0.04 0.00 0.00]\n",
      " [0.03 0.03 0.03 0.00 -0.00 0.02 -0.08 0.03 -0.09 0.00 0.05 0.02 0.02 0.02 0.03 0.01 0.00 0.02 0.00 0.00]\n",
      " [0.06 -0.06 0.02 0.05 0.01 0.03 -0.35 -0.05 -0.26 0.05 0.00 0.00 0.04 -0.03 0.03 0.00 0.02 0.00 0.00 0.00]\n",
      " [0.04 0.02 0.02 0.03 0.00 0.02 -0.25 0.03 -0.08 0.02 0.00 0.00 0.02 0.02 0.03 0.00 0.01 0.00 0.00 0.00]\n",
      " [0.00 0.02 0.03 0.06 0.05 0.04 -0.27 0.02 -0.14 -0.13 0.04 -0.01 0.00 0.04 0.00 -0.06 0.01 0.00 0.00 0.00]\n",
      " [0.05 0.05 0.06 0.04 0.00 -0.00 -0.07 0.03 -0.11 0.02 0.02 0.02 0.00 0.00 0.01 0.04 0.02 0.01 0.00 0.00]\n",
      " [0.02 0.02 0.02 0.01 0.02 0.01 0.00 0.00 -0.02 0.03 0.03 0.03 -0.02 0.01 0.00 0.02 0.02 0.01 0.00 0.00]\n",
      " [0.05 0.02 0.03 0.04 0.00 0.04 -0.29 0.03 -0.20 -0.02 0.00 0.00 0.04 0.04 0.02 -0.00 0.01 0.00 0.00 0.00]\n",
      " [0.02 0.04 0.04 0.03 0.02 0.02 0.04 0.03 0.04 0.00 -0.03 0.01 -0.06 0.02 0.02 0.01 -0.00 0.03 0.00 0.00]\n",
      " [0.01 0.03 0.02 0.01 -0.00 0.01 0.05 0.01 0.04 0.02 -0.14 0.00 -0.16 -0.09 -0.11 0.00 -0.51 -0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "mask = 1 - global_edit_A[0][i][j].squeeze(-1).numpy().astype(int)\n",
    "\n",
    "print(global_edit_A[1][i][j].squeeze(-1).numpy().astype(int) - global_edit_A[0][i][j].squeeze(-1).numpy().astype(int))\n",
    "print()\n",
    "print(mask * (global_norm_A[1][i][j].squeeze(-1).numpy() - global_norm_A[0][i][j].squeeze(-1).numpy()))\n",
    "print(\"========================================================================\")\n",
    "print(global_edit_A[2][i][j].squeeze(-1).numpy().astype(int) - global_edit_A[1][i][j].squeeze(-1).numpy().astype(int))\n",
    "print()\n",
    "print(mask * (global_norm_A[2][i][j].squeeze(-1).numpy() - global_norm_A[1][i][j].squeeze(-1).numpy()))\n",
    "print()\n",
    "print(mask * (global_norm_A[2][i][j].squeeze(-1).numpy() - global_norm_A[0][i][j].squeeze(-1).numpy()))\n",
    "print(\"========================================================================\")\n",
    "print(global_edit_A[3][i][j].squeeze(-1).numpy().astype(int) - global_edit_A[2][i][j].squeeze(-1).numpy().astype(int))\n",
    "print()\n",
    "print(mask * (global_norm_A[3][i][j].squeeze(-1).numpy() - global_norm_A[2][i][j].squeeze(-1).numpy()))\n",
    "print()\n",
    "print(mask * (global_norm_A[3][i][j].squeeze(-1).numpy() - global_norm_A[0][i][j].squeeze(-1).numpy()))\n",
    "\n",
    "print(\"========================================================================\")\n",
    "print(global_edit_A[4][i][j].squeeze(-1).numpy().astype(int) - global_edit_A[3][i][j].squeeze(-1).numpy().astype(int))\n",
    "print()\n",
    "print(mask * (global_norm_A[4][i][j].squeeze(-1).numpy() - global_norm_A[3][i][j].squeeze(-1).numpy()))\n",
    "print()\n",
    "print(mask * (global_norm_A[4][i][j].squeeze(-1).numpy() - global_norm_A[0][i][j].squeeze(-1).numpy()))\n",
    "\n",
    "print(\"========================================================================\")\n",
    "print(global_edit_A[5][i][j].squeeze(-1).numpy().astype(int) - global_edit_A[4][i][j].squeeze(-1).numpy().astype(int))\n",
    "print()\n",
    "print(mask * (global_norm_A[5][i][j].squeeze(-1).numpy() - global_norm_A[4][i][j].squeeze(-1).numpy()))\n",
    "print()\n",
    "print(mask * (global_norm_A[5][i][j].squeeze(-1).numpy() - global_norm_A[0][i][j].squeeze(-1).numpy()))\n",
    "\n",
    "print(\"========================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "# print()\n",
    "# print(global_norm_A[3][i][j].squeeze(-1).numpy() - global_norm_A[2][i][j].squeeze(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_edit_A[5][i][j].squeeze(-1).numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67 0.40 0.49 0.60 0.67 0.46 0.56 0.43 0.56 0.32 0.54 0.40 0.56 0.44 0.18 0.54 0.21 0.05 0.00 0.00]\n",
      " [0.40 0.61 0.67 0.36 0.65 0.49 0.37 0.44 0.68 0.30 0.29 0.16 0.32 0.47 0.18 0.22 0.35 0.25 0.00 0.00]\n",
      " [0.49 0.67 0.74 0.43 0.71 0.65 0.36 0.51 0.63 0.32 0.42 0.21 0.38 0.54 0.21 0.27 0.36 0.22 0.00 0.00]\n",
      " [0.60 0.36 0.43 0.79 0.69 0.40 0.38 0.31 0.39 0.58 0.49 0.26 0.55 0.39 0.11 0.52 0.32 0.07 0.00 0.00]\n",
      " [0.60 0.62 0.71 0.69 0.87 0.63 0.29 0.45 0.61 0.63 0.33 0.26 0.43 0.56 0.16 0.29 0.41 0.16 0.00 0.00]\n",
      " [0.46 0.49 0.56 0.40 0.83 0.59 0.30 0.33 0.48 0.17 0.24 0.22 0.34 0.58 0.12 0.34 0.17 0.11 0.00 0.00]\n",
      " [0.10 0.37 0.36 0.13 0.34 0.19 0.55 0.25 0.47 0.23 0.19 0.03 0.25 0.25 0.15 0.03 0.94 0.62 0.00 0.00]\n",
      " [0.43 0.44 0.51 0.31 0.50 0.33 0.40 0.56 0.53 0.32 0.33 0.32 0.17 0.30 0.33 0.33 0.30 0.16 0.00 0.00]\n",
      " [0.25 0.54 0.57 0.26 0.51 0.39 0.47 0.37 0.68 0.24 0.24 0.08 0.38 0.48 0.16 0.11 0.49 0.35 0.00 0.00]\n",
      " [0.32 0.30 0.32 0.46 0.55 0.18 0.35 0.32 0.37 0.87 0.43 0.18 0.19 0.15 0.27 0.14 0.63 0.17 0.00 0.00]\n",
      " [0.54 0.26 0.22 0.49 0.36 0.24 0.44 0.43 0.39 0.43 0.76 0.53 0.39 0.28 0.28 0.53 0.17 0.01 0.00 0.00]\n",
      " [0.40 0.16 0.21 0.26 0.22 0.22 0.33 0.32 0.18 0.18 0.53 0.48 0.23 0.21 0.25 0.52 0.06 0.03 0.00 0.00]\n",
      " [0.44 0.21 0.25 0.55 0.43 0.34 0.37 0.15 0.32 0.37 0.39 0.27 0.54 0.35 0.04 0.45 0.08 0.02 0.00 0.00]\n",
      " [0.44 0.47 0.54 0.39 0.56 0.82 0.29 0.30 0.55 0.15 0.23 0.21 0.39 0.58 0.11 0.33 0.14 0.11 0.00 0.00]\n",
      " [0.18 0.18 0.21 0.11 0.16 0.12 0.17 0.33 0.20 0.27 0.28 0.25 0.08 0.11 0.34 0.17 0.19 0.11 0.00 0.00]\n",
      " [0.50 0.22 0.27 0.34 0.29 0.34 0.39 0.33 0.37 0.18 0.54 0.50 0.33 0.33 0.17 0.74 0.07 0.03 0.00 0.00]\n",
      " [0.21 0.35 0.36 0.32 0.43 0.17 0.38 0.30 0.34 0.63 0.22 0.06 0.16 0.14 0.19 0.07 0.86 0.32 0.00 0.00]\n",
      " [0.05 0.25 0.22 0.07 0.19 0.11 0.47 0.17 0.35 0.17 0.18 0.03 0.21 0.24 0.26 0.03 0.97 0.68 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n",
      "\n",
      "[[0.74 0.44 0.54 0.66 0.68 0.51 0.19 0.48 0.33 0.35 0.60 0.45 0.50 0.49 0.20 0.56 0.23 0.05 0.00 0.00]\n",
      " [0.44 0.68 0.74 0.40 0.70 0.54 0.41 0.49 0.62 0.33 0.21 0.18 0.25 0.52 0.20 0.24 0.39 0.27 0.00 0.00]\n",
      " [0.54 0.74 0.82 0.47 0.79 0.64 0.40 0.56 0.64 0.36 0.28 0.23 0.30 0.60 0.24 0.30 0.40 0.25 0.00 0.00]\n",
      " [0.66 0.40 0.47 0.87 0.76 0.44 0.19 0.34 0.30 0.53 0.54 0.29 0.61 0.43 0.12 0.41 0.35 0.08 0.00 0.00]\n",
      " [0.67 0.69 0.79 0.76 0.97 0.65 0.33 0.50 0.58 0.52 0.36 0.25 0.48 0.62 0.18 0.32 0.45 0.18 0.00 0.00]\n",
      " [0.51 0.54 0.62 0.44 0.68 0.65 0.23 0.36 0.44 0.19 0.26 0.25 0.37 0.64 0.13 0.38 0.18 0.12 0.00 0.00]\n",
      " [0.12 0.41 0.40 0.14 0.33 0.21 0.61 0.28 0.52 0.25 0.05 0.04 0.08 0.22 0.17 0.04 0.51 0.55 0.00 0.00]\n",
      " [0.48 0.49 0.56 0.34 0.51 0.36 0.30 0.62 0.42 0.36 0.37 0.35 0.17 0.33 0.36 0.36 0.33 0.18 0.00 0.00]\n",
      " [0.28 0.60 0.63 0.28 0.57 0.43 0.52 0.39 0.65 0.26 0.10 0.09 0.19 0.43 0.18 0.12 0.40 0.38 0.00 0.00]\n",
      " [0.35 0.33 0.36 0.50 0.51 0.19 0.27 0.36 0.29 0.97 0.48 0.20 0.21 0.17 0.30 0.15 0.70 0.19 0.00 0.00]\n",
      " [0.60 0.20 0.25 0.54 0.37 0.26 0.09 0.38 0.13 0.48 0.84 0.58 0.43 0.26 0.31 0.58 0.19 0.01 0.00 0.00]\n",
      " [0.45 0.18 0.23 0.29 0.24 0.25 0.09 0.35 0.10 0.20 0.58 0.53 0.26 0.24 0.28 0.55 0.07 0.04 0.00 0.00]\n",
      " [0.48 0.23 0.28 0.61 0.48 0.37 0.10 0.16 0.18 0.24 0.43 0.26 0.59 0.39 0.05 0.39 0.09 0.02 0.00 0.00]\n",
      " [0.49 0.52 0.60 0.43 0.62 0.68 0.22 0.33 0.44 0.17 0.25 0.24 0.39 0.65 0.12 0.37 0.16 0.12 0.00 0.00]\n",
      " [0.20 0.20 0.24 0.12 0.18 0.13 0.17 0.36 0.18 0.30 0.31 0.28 0.06 0.12 0.37 0.19 0.21 0.12 0.00 0.00]\n",
      " [0.56 0.24 0.30 0.38 0.32 0.38 0.10 0.36 0.17 0.16 0.58 0.55 0.37 0.37 0.19 0.74 0.07 0.04 0.00 0.00]\n",
      " [0.23 0.39 0.40 0.35 0.45 0.18 0.42 0.33 0.38 0.70 0.20 0.07 0.10 0.16 0.21 0.07 0.76 0.35 0.00 0.00]\n",
      " [0.05 0.27 0.25 0.08 0.18 0.12 0.52 0.18 0.38 0.19 0.04 0.04 0.05 0.14 0.15 0.04 0.46 0.54 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]\n",
      " [0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00]]\n"
     ]
    }
   ],
   "source": [
    "print(global_norm_A[0][i][j].squeeze(-1).numpy())\n",
    "print()\n",
    "print(global_norm_A[5][i][j].squeeze(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
